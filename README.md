# Adam_MiniBatch_Gradient_Descent
Implementing Adam Optimizer from scratch With Full/Mini Batch 
